{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSU7/kM6/FM5H0NHwWjNCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clare9766/Size-probability-conversion-method/blob/main/Size_Probability_Based_Method_English_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9w_elHU66H",
        "outputId": "1738b3a4-15c2-4c4d-940e-e90eeac9f3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Data/Mass/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uATjiG-vVKhz",
        "outputId": "5e9e5d64-1bd8-403e-b2e0-71d2740e6267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data/Mass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Description:\n",
        "## Variables include:\n",
        "## - 'ID' (unique, cannot be repeated)\n",
        "## - Total abundance count, Proportion of fibers and fragments ('Fiber Number Concentration' and 'Fragment Number Concentration')\n",
        "## - 'Converted Size Mid-point' (list)\n",
        "## - 'PDF' or 'CDF' of the size distribution (list)\n",
        "##   - If provided as PDF, it must be converted to CDF\n",
        "## - Converted unit: grams (g)"
      ],
      "metadata": {
        "id": "sqGiUymxNxeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert PDF data to CDF (Optional)"
      ],
      "metadata": {
        "id": "UtC8qsvgVX0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Read Excel file\n",
        "df = pd.read_excel(\"combine0515.xlsx\")\n",
        "\n",
        "# Define a function to parse PDF strings\n",
        "def parse_pdf_string(pdf_str, row_index):\n",
        "    try:\n",
        "        if isinstance(pdf_str, str):\n",
        "            if not pdf_str.strip().startswith(\"[\"):\n",
        "                pdf_str = \"[\" + pdf_str.strip() + \"]\"\n",
        "            return ast.literal_eval(pdf_str)\n",
        "        elif isinstance(pdf_str, list):\n",
        "            return pdf_str\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed to parse PDF in row {row_index+2}: {pdf_str}, Error: {e}\")\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to convert PDF to CDF\n",
        "def convert_pdf_to_cdf(pdf_list):\n",
        "    if isinstance(pdf_list, list) and all(isinstance(x, (int, float)) for x in pdf_list):\n",
        "        cdf_vals = np.cumsum(pdf_list)\n",
        "        return [round(float(x), 5) for x in cdf_vals]  # Convert to float and keep 5 decimals\n",
        "    return np.nan\n",
        "\n",
        "# Parse PDF and generate CDF\n",
        "df['PDF_list'] = [parse_pdf_string(val, idx) for idx, val in enumerate(df['PDF'])]\n",
        "df['CDF'] = df['PDF_list'].apply(convert_pdf_to_cdf)\n",
        "\n",
        "# Drop temporary column (optional)\n",
        "df.drop(columns=['PDF_list'], inplace=True)\n",
        "\n",
        "# Export to a new file\n",
        "df.to_excel(\"combine0515_with_CDF_cleaned.xlsx\", index=False)\n",
        "\n",
        "print(\"✅ Processing completed. Results saved as 'combine_with_CDF_cleaned.xlsx'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhfgCZr85EZG",
        "outputId": "a10bd4ec-6212-4885-c81f-c36b1712a2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processing completed. Results saved as 'combine_with_CDF_cleaned.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting Parameter"
      ],
      "metadata": {
        "id": "TgQ4G4DK7hUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import linregress\n",
        "import ast\n",
        "\n",
        "file_path = '10.22.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')  # , sheet_name=\"Mass Spectrometry based\"\n",
        "\n",
        "\n",
        "# Define CDF functions\n",
        "xmin = 0.1\n",
        "\n",
        "\n",
        "def cdf_functionCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "# def pdf_functionCFD(x, lambd, alpha):\n",
        "#     return lambd * alpha * x**(alpha - 1) * np.exp(-lambd * x**alpha)\n",
        "\n",
        "\n",
        "# Define the main fitting function\n",
        "def merge_and_fit_cdf(data_df):\n",
        "    para_samples = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        if pd.isna(row['Converted Size Mid-point']) or pd.isna(row['CDF']):\n",
        "            # print(f\"⚠️ Row {idx+1} skipped due to missing data.\")\n",
        "            continue  # Skip this row\n",
        "\n",
        "        try:\n",
        "            x_intervals = np.array(ast.literal_eval(row['Converted Size Mid-point'])).flatten()\n",
        "            y_probs = np.array(ast.literal_eval(row['CDF'])).flatten()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Row {idx+1} parsing failed: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Fit using curve_fit (CFD model)\n",
        "            params_CFD, covariance = curve_fit(cdf_functionCFD, x_intervals, y_probs, p0=[1.0, 1.0])\n",
        "\n",
        "            # Extract fitted parameters\n",
        "            alpha_CFD, lambd_CFD = params_CFD\n",
        "\n",
        "            # Compute R² for CFD model\n",
        "            y_fit = cdf_functionCFD(x_intervals, *params_CFD)\n",
        "            slope, intercept, r_CFD, p_CFD, std_err = linregress(y_probs, y_fit)\n",
        "            r2_CFD = r_CFD**2\n",
        "\n",
        "        except (RuntimeError, ValueError, SyntaxError) as e:\n",
        "            print(f\"Error at row {idx+1}: {e}\")\n",
        "            continue\n",
        "            alpha_CFD, lambd_CFD, r2_CFD, p_CFD = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        para_samples.append({\n",
        "            'ID': row['ID'],\n",
        "            'Alpha_CFD': alpha_CFD,\n",
        "            'Lambda_CFD': lambd_CFD,\n",
        "            'R2_CFD': r2_CFD,\n",
        "            'p_value_CFD': p_CFD,\n",
        "        })\n",
        "    return pd.DataFrame(para_samples)\n",
        "\n",
        "\n",
        "# Run the fitting function\n",
        "para_samples = merge_and_fit_cdf(data_df)\n",
        "merged_df = pd.merge(data_df, para_samples, on='ID', how='left')\n",
        "merged_df.to_excel(file_path, index=False)\n",
        "print(f\"✅ Results successfully saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P7En_CfVMFL",
        "outputId": "b929f3d1-9a09-41cf-e17b-f906dc5d9b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error at row 131: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 134: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 137: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 142: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 153: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 158: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 160: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 162: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 163: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-75101966.py:41: OptimizeWarning: Covariance of the parameters could not be estimated\n",
            "  params_CFD, covariance = curve_fit(cdf_functionCFD, x_intervals, y_probs, p0=[1.0, 1.0])\n",
            "/tmp/ipython-input-75101966.py:17: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 - np.exp(-lambd * x**alpha)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error at row 215: Cannot calculate a linear regression if all x values are identical\n",
            "Error at row 219: Cannot calculate a linear regression if all x values are identical\n",
            "Error at row 344: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 354: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 355: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 361: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 362: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 363: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 364: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 365: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 366: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 367: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 368: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 369: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 627: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 628: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 629: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 630: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 631: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 632: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 883: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 890: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 895: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 918: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "✅ Results successfully saved to 10.22.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mass Calculation"
      ],
      "metadata": {
        "id": "UpumK57XUW6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mass Calculation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.integrate import quad\n",
        "\n",
        "# File path\n",
        "file_path = '10.22_fitting_process.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "R_fiber = 0.01\n",
        "Rho_fiber = 1.35\n",
        "Rho_fragment = 0.92\n",
        "xmin = 0.1\n",
        "\n",
        "x_intervals = [0.1]\n",
        "\n",
        "\n",
        "def calculate_cdfCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "def calculate_interval_particles(cdf_func, x_min, x_max, total_data, **params):\n",
        "    return total_data * (cdf_func(x_max, **params) - cdf_func(x_min, **params)) / cdf_func(5 + xmin, **params)\n",
        "\n",
        "# Calculate fiber mass\n",
        "def calculate_fiber_mass_cylinder_Simon6(L):\n",
        "    return np.pi * R_fiber**2 * L * Rho_fiber * 0.6 / 1000\n",
        "\n",
        "# Calculate fragment mass\n",
        "def calculate_fragment_mass_elliosoid_Han(L):\n",
        "    return np.pi / 6 * L**2 * 0.02 * Rho_fragment / 1000\n",
        "\n",
        "methods = {\n",
        "    \"CFD\": {\n",
        "        \"fiber_cdf\": calculate_cdfCFD,\n",
        "        \"fiber_mass\": calculate_fiber_mass_cylinder_Simon6,\n",
        "        \"fragment_cdf\": calculate_cdfCFD,\n",
        "        \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    },\n",
        "}\n",
        "\n",
        "def save_mass_data(interval):\n",
        "    data = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        results = {\"ID\": row['ID']}  # {\"ID\": idx + 1}\n",
        "        fiber_size = row['Fiber Number Concentration']\n",
        "        fragment_size = row['Fragment Number Concentration']\n",
        "        alp_CFD = row['Alpha_CFD']\n",
        "        lam_CFD = row['Lambda_CFD']\n",
        "\n",
        "        for method_name, method in methods.items():\n",
        "            total_fiber_mass = 0\n",
        "            total_fragment_mass = 0\n",
        "\n",
        "            for i in np.arange(xmin, 5 + xmin, interval):\n",
        "                mid_point = i + interval / 2\n",
        "\n",
        "                if method['fiber_cdf'] == calculate_cdfCFD:\n",
        "                    fiber_particles = calculate_interval_particles(\n",
        "                        method['fiber_cdf'], i, i + interval, fiber_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "\n",
        "                fiber_mass = fiber_particles * method['fiber_mass'](mid_point)\n",
        "                total_fiber_mass += fiber_mass\n",
        "\n",
        "                if method['fragment_cdf'] == calculate_cdfCFD:\n",
        "                    fragment_particles = calculate_interval_particles(\n",
        "                        method['fragment_cdf'], i, i + interval, fragment_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "                fragment_mass = fragment_particles * method['fragment_mass'](mid_point)\n",
        "                total_fragment_mass += fragment_mass\n",
        "\n",
        "            total_mass = total_fiber_mass + total_fragment_mass\n",
        "\n",
        "            results[f\"Fiber Mass ({method_name})\"] = total_fiber_mass\n",
        "            results[f\"Fragment Mass ({method_name})\"] = total_fragment_mass\n",
        "            results[f\"Total Mass ({method_name})\"] = total_mass\n",
        "            # results[f\"b/a{method_name}\"] = balance / total_mass\n",
        "            # results[f\"a/b{method_name}\"] = total_mass / balance\n",
        "            # results[f\"RE{method_name}\"] = abs(total_mass - balance) / balance\n",
        "            # results[f\"SE{method_name}\"] = (total_mass - balance)**2\n",
        "\n",
        "        data.append(results)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    merged_df = pd.merge(data_df, df, on='ID', how='left')\n",
        "    merged_df.to_excel(file_path, index=False)\n",
        "    print(f\"✅ Results successfully saved to {file_path}\")\n",
        "\n",
        "for interval in x_intervals:\n",
        "    save_mass_data(interval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "T19SGcV9UW6C",
        "outputId": "4b2a1497-2241-4fac-8259-4364848000e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Alpha_CFD'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Alpha_CFD'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3085032953.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_intervals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0msave_mass_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3085032953.py\u001b[0m in \u001b[0;36msave_mass_data\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mfiber_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fiber Number Concentration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mfragment_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fragment Number Concentration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0malp_CFD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alpha_CFD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mlam_CFD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lambda_CFD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Alpha_CFD'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Below-CFD and CPD version"
      ],
      "metadata": {
        "id": "5i7CUO_6UcoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting Parameter"
      ],
      "metadata": {
        "id": "S2652247UQK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import linregress\n",
        "import ast\n",
        "\n",
        "file_path = '10.22.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')  # , sheet_name=\"Mass Spectrometry based\"\n",
        "\n",
        "\n",
        "# Define CDF functions\n",
        "xmin = 0.1\n",
        "\n",
        "def cdf_functionCPD(x, alpha):\n",
        "    return 1 - (x ** (1 - alpha)) * (xmin ** (alpha - 1))\n",
        "\n",
        "def pdf_functionCPD(x, alpha):\n",
        "    return (alpha - 1) * xmin**(alpha - 1) * x ** (-alpha)\n",
        "\n",
        "def cdf_functionCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "def pdf_functionCFD(x, lambd, alpha):\n",
        "    return lambd * alpha * x**(alpha - 1) * np.exp(-lambd * x**alpha)\n",
        "\n",
        "\n",
        "# Define the main fitting function\n",
        "def merge_and_fit_cdf(data_df):\n",
        "    para_samples = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        if pd.isna(row['Converted Size Mid-point']) or pd.isna(row['CDF']):\n",
        "            # print(f\"⚠️ Row {idx+1} skipped due to missing data.\")\n",
        "            continue  # Skip this row\n",
        "\n",
        "        try:\n",
        "            x_intervals = np.array(ast.literal_eval(row['Converted Size Mid-point'])).flatten()\n",
        "            y_probs = np.array(ast.literal_eval(row['CDF'])).flatten()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Row {idx+1} parsing failed: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Fit using curve_fit (CFD model)\n",
        "            params_CFD, covariance = curve_fit(cdf_functionCFD, x_intervals, y_probs, p0=[1.0, 1.0])\n",
        "\n",
        "            # Extract fitted parameters\n",
        "            alpha_CFD, lambd_CFD = params_CFD\n",
        "\n",
        "            # Compute R² for CFD model\n",
        "            y_fit = cdf_functionCFD(x_intervals, *params_CFD)\n",
        "            slope, intercept, r_CFD, p_CFD, std_err = linregress(y_probs, y_fit)\n",
        "            r2_CFD = r_CFD**2\n",
        "\n",
        "        except (RuntimeError, ValueError, SyntaxError) as e:\n",
        "            print(f\"Error at row {idx+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Fit using curve_fit (CPD model)\n",
        "            params_CPD, covariance = curve_fit(cdf_functionCPD, x_intervals, y_probs)\n",
        "\n",
        "            # Extract fitted parameter\n",
        "            alpha_CPD = params_CPD[0]\n",
        "\n",
        "            # Compute R² for CPD model\n",
        "            y_fit = cdf_functionCPD(x_intervals, alpha_CPD)\n",
        "            slope, intercept, r_CPD, p_CPD, std_err = linregress(y_probs, y_fit)\n",
        "            r2_CPD = r_CPD**2\n",
        "\n",
        "        except RuntimeError:\n",
        "            print(f\"Curve fitting failed for CPD in row {idx}.\")\n",
        "            alpha_CPD, lambd_CPD, r2_CPD, p_CPD = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        para_samples.append({\n",
        "            'ID': row['ID'],\n",
        "            'Alpha_CPD': alpha_CPD,\n",
        "            'R2_CPD': r2_CPD,\n",
        "            'p_value_CPD': p_CPD,\n",
        "            'Alpha_CFD': alpha_CFD,\n",
        "            'Lambda_CFD': lambd_CFD,\n",
        "            'R2_CFD': r2_CFD,\n",
        "            'p_value_CFD': p_CFD,\n",
        "        })\n",
        "    return pd.DataFrame(para_samples)\n",
        "\n",
        "\n",
        "# Run the fitting function\n",
        "para_samples = merge_and_fit_cdf(data_df)\n",
        "merged_df = pd.merge(data_df, para_samples, on='ID', how='left')\n",
        "merged_df.to_excel(file_path, index=False)\n",
        "print(f\"✅ Results successfully saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41d674e-9ecf-4a3a-8b85-8ac8d1496b8f",
        "id": "bY55bMbMUQK6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error at row 131: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 134: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 137: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 142: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 153: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 158: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 160: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 162: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 163: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 215: Cannot calculate a linear regression if all x values are identical\n",
            "Error at row 219: Cannot calculate a linear regression if all x values are identical\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2376783464.py:47: OptimizeWarning: Covariance of the parameters could not be estimated\n",
            "  params_Hou, covariance = curve_fit(cdf_functionHou, x_intervals, y_probs, p0=[1.0, 1.0])\n",
            "/tmp/ipython-input-2376783464.py:22: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 - np.exp(-lambd * x**alpha)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error at row 344: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 354: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 355: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 361: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 362: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 363: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 364: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 365: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 366: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 367: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 368: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 369: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 627: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 628: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 629: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 630: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 631: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 632: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 883: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 890: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 895: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Error at row 918: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\n",
            "Results successfully saved to 10.22.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mass Calculation"
      ],
      "metadata": {
        "id": "gaVEM6waVoQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mass Calculation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.integrate import quad\n",
        "\n",
        "# File path\n",
        "file_path = '10.22_fitting_process.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "R_fiber = 0.01\n",
        "Rho_fiber = 1.35\n",
        "Rho_fragment = 0.92\n",
        "xmin = 0.1\n",
        "\n",
        "x_intervals = [0.1]\n",
        "\n",
        "def calculate_cdfCPD(x, alpha):\n",
        "    return 1 - (x ** (1 - alpha)) * (xmin ** (alpha - 1))\n",
        "\n",
        "def calculate_cdfCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "def calculate_interval_particles(cdf_func, x_min, x_max, total_data, **params):\n",
        "    return total_data * (cdf_func(x_max, **params) - cdf_func(x_min, **params)) / cdf_func(5 + xmin, **params)\n",
        "\n",
        "# Calculate fiber mass\n",
        "def calculate_fiber_mass_cylinder_Simon6(L):\n",
        "    return np.pi * R_fiber**2 * L * Rho_fiber * 0.6 / 1000\n",
        "\n",
        "def calculate_fiber_mass_cylinder_Simon7(L):\n",
        "    return np.pi * R_fiber**2 * L * Rho_fiber * 0.7 / 1000\n",
        "\n",
        "def calculate_fiber_mass_cylinder_Simon1(L):\n",
        "    return np.pi * R_fiber**2 * L * Rho_fiber * 1 / 1000\n",
        "\n",
        "# Calculate fragment mass\n",
        "def calculate_fragment_mass_elliosoid_Han(L):\n",
        "    return np.pi / 6 * L**2 * 0.02 * Rho_fragment / 1000\n",
        "\n",
        "methods = {\n",
        "    \"CFD\": {\n",
        "        \"fiber_cdf\": calculate_cdfCFD,\n",
        "        \"fiber_mass\": calculate_fiber_mass_cylinder_Simon6,\n",
        "        \"fragment_cdf\": calculate_cdfCFD,\n",
        "        \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    },\n",
        "    # \"Method 4\": {\n",
        "    #     \"fiber_cdf\": calculate_cdfCFD,\n",
        "    #     \"fiber_mass\": calculate_fiber_mass_cylinder_Simon7,\n",
        "    #     \"fragment_cdf\": calculate_cdfCFD,\n",
        "    #     \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    # },\n",
        "    # \"Method 7\": {\n",
        "    #     \"fiber_cdf\": calculate_cdfCPD,\n",
        "    #     \"fiber_mass\": calculate_fiber_mass_cylinder_Simon7,\n",
        "    #     \"fragment_cdf\": calculate_cdfCFD,\n",
        "    #     \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    # },\n",
        "    # \"Method 10\": {\n",
        "    #     \"fiber_cdf\": calculate_cdfCPD,\n",
        "    #     \"fiber_mass\": calculate_fiber_mass_cylinder_Simon1,\n",
        "    #     \"fragment_cdf\": calculate_cdfCFD,\n",
        "    #     \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    # }\n",
        "}\n",
        "\n",
        "def save_mass_data(interval):\n",
        "    data = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        results = {\"ID\": row['ID']}  # {\"ID\": idx + 1}\n",
        "        fiber_size = row['Fiber Number Concentration']\n",
        "        fragment_size = row['Fragment Number Concentration']\n",
        "        # balance = row['Mass']\n",
        "        # number = row['Number']\n",
        "        alp_CPD = row['Alpha_CPD']\n",
        "        alp_CFD = row['Alpha_CFD']\n",
        "        lam_CFD = row['Lambda_CFD']\n",
        "\n",
        "        for method_name, method in methods.items():\n",
        "            total_fiber_mass = 0\n",
        "            total_fragment_mass = 0\n",
        "\n",
        "            for i in np.arange(xmin, 5 + xmin, interval):\n",
        "                mid_point = i + interval / 2\n",
        "\n",
        "                if method['fiber_cdf'] == calculate_cdfCFD:\n",
        "                    fiber_particles = calculate_interval_particles(\n",
        "                        method['fiber_cdf'], i, i + interval, fiber_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "                else:\n",
        "                    fiber_particles = calculate_interval_particles(\n",
        "                        method['fiber_cdf'], i, i + interval, fiber_size,\n",
        "                        alpha=alp_CPD\n",
        "                    )\n",
        "\n",
        "                fiber_mass = fiber_particles * method['fiber_mass'](mid_point)\n",
        "                total_fiber_mass += fiber_mass\n",
        "\n",
        "                if method['fragment_cdf'] == calculate_cdfCFD:\n",
        "                    fragment_particles = calculate_interval_particles(\n",
        "                        method['fragment_cdf'], i, i + interval, fragment_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "                else:\n",
        "                    fragment_particles = calculate_interval_particles(\n",
        "                        method['fragment_cdf'], i, i + interval, fragment_size,\n",
        "                        alpha=alp_CPD\n",
        "                    )\n",
        "                fragment_mass = fragment_particles * method['fragment_mass'](mid_point)\n",
        "                total_fragment_mass += fragment_mass\n",
        "\n",
        "            total_mass = total_fiber_mass + total_fragment_mass\n",
        "            # print(f\"IDX: {idx}\")\n",
        "\n",
        "            results[f\"Fiber Mass ({method_name})\"] = total_fiber_mass\n",
        "            results[f\"Fragment Mass ({method_name})\"] = total_fragment_mass\n",
        "            results[f\"Total Mass ({method_name})\"] = total_mass\n",
        "            # results[f\"b/a{method_name}\"] = balance / total_mass\n",
        "            # results[f\"a/b{method_name}\"] = total_mass / balance\n",
        "            # results[f\"RE{method_name}\"] = abs(total_mass - balance) / balance\n",
        "            # results[f\"SE{method_name}\"] = (total_mass - balance)**2\n",
        "\n",
        "        data.append(results)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    merged_df = pd.merge(data_df, df, on='ID', how='left')\n",
        "    merged_df.to_excel(file_path, index=False)\n",
        "    print(f\"✅ Results successfully saved to {file_path}\")\n",
        "\n",
        "for interval in x_intervals:\n",
        "    save_mass_data(interval)\n"
      ],
      "metadata": {
        "id": "thHgmqNwSyhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}