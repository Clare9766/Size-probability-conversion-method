{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEoCI0K7dFPcWz8/fhUUJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clare9766/Size-probability-conversion-method/blob/main/Size_Probability_Based_Method_English_Version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9w_elHU66H",
        "outputId": "1738b3a4-15c2-4c4d-940e-e90eeac9f3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Data/Mass/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uATjiG-vVKhz",
        "outputId": "5e9e5d64-1bd8-403e-b2e0-71d2740e6267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data/Mass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Description:\n",
        "## Variables include:\n",
        "## - 'ID' (unique, cannot be repeated)\n",
        "## - Total abundance count, Proportion of fibers and fragments ('Fiber Number Concentration' and 'Fragment Number Concentration')\n",
        "## - 'Converted Size Mid-point' (list)\n",
        "## - 'PDF' or 'CDF' of the size distribution (list)\n",
        "##   - If provided as PDF, it must be converted to CDF\n",
        "## - Converted unit: grams (g)"
      ],
      "metadata": {
        "id": "sqGiUymxNxeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert PDF data to CDF (Optional)"
      ],
      "metadata": {
        "id": "UtC8qsvgVX0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Read Excel file\n",
        "df = pd.read_excel(\"DATA_WITH_PDF_LIST.xlsx\")\n",
        "\n",
        "# Define a function to parse PDF strings\n",
        "def parse_pdf_string(pdf_str, row_index):\n",
        "    try:\n",
        "        if isinstance(pdf_str, str):\n",
        "            if not pdf_str.strip().startswith(\"[\"):\n",
        "                pdf_str = \"[\" + pdf_str.strip() + \"]\"\n",
        "            return ast.literal_eval(pdf_str)\n",
        "        elif isinstance(pdf_str, list):\n",
        "            return pdf_str\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed to parse PDF in row {row_index+2}: {pdf_str}, Error: {e}\")\n",
        "        return np.nan\n",
        "\n",
        "# Define a function to convert PDF to CDF\n",
        "def convert_pdf_to_cdf(pdf_list):\n",
        "    if isinstance(pdf_list, list) and all(isinstance(x, (int, float)) for x in pdf_list):\n",
        "        cdf_vals = np.cumsum(pdf_list)\n",
        "        return [round(float(x), 5) for x in cdf_vals]  # Convert to float and keep 5 decimals\n",
        "    return np.nan\n",
        "\n",
        "# Parse PDF and generate CDF\n",
        "df['PDF_list'] = [parse_pdf_string(val, idx) for idx, val in enumerate(df['PDF'])]\n",
        "df['CDF'] = df['PDF_list'].apply(convert_pdf_to_cdf)\n",
        "\n",
        "# Drop temporary column (optional)\n",
        "df.drop(columns=['PDF_list'], inplace=True)\n",
        "\n",
        "# Export to a new file\n",
        "df.to_excel(\"DATA_WITH_CDF_LIST.xlsx\", index=False)\n",
        "\n",
        "print(\"✅ Processing completed. Results saved as 'DATA_WITH_CDF_LIST.xlsx'\")"
      ],
      "metadata": {
        "id": "mhfgCZr85EZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting Parameter"
      ],
      "metadata": {
        "id": "TgQ4G4DK7hUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import linregress\n",
        "import ast\n",
        "\n",
        "file_path = 'DATA_WITH_CDF_LIST.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "\n",
        "# Define CDF functions\n",
        "xmin = 0.1\n",
        "\n",
        "\n",
        "def cdf_functionCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "# def pdf_functionCFD(x, lambd, alpha):\n",
        "#     return lambd * alpha * x**(alpha - 1) * np.exp(-lambd * x**alpha)\n",
        "\n",
        "\n",
        "# Define the main fitting function\n",
        "def merge_and_fit_cdf(data_df):\n",
        "    para_samples = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        if pd.isna(row['Converted Size Mid-point']) or pd.isna(row['CDF']):\n",
        "            # print(f\"⚠️ Row {idx+1} skipped due to missing data.\")\n",
        "            continue  # Skip this row\n",
        "\n",
        "        try:\n",
        "            x_intervals = np.array(ast.literal_eval(row['Converted Size Mid-point'])).flatten()\n",
        "            y_probs = np.array(ast.literal_eval(row['CDF'])).flatten()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Row {idx+1} parsing failed: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Fit using curve_fit (CFD model)\n",
        "            params_CFD, covariance = curve_fit(cdf_functionCFD, x_intervals, y_probs, p0=[1.0, 1.0])\n",
        "\n",
        "            # Extract fitted parameters\n",
        "            alpha_CFD, lambd_CFD = params_CFD\n",
        "\n",
        "            # Compute R² for CFD model\n",
        "            y_fit = cdf_functionCFD(x_intervals, *params_CFD)\n",
        "            slope, intercept, r_CFD, p_CFD, std_err = linregress(y_probs, y_fit)\n",
        "            r2_CFD = r_CFD**2\n",
        "\n",
        "        except (RuntimeError, ValueError, SyntaxError) as e:\n",
        "            print(f\"Error at row {idx+1}: {e}\")\n",
        "            continue\n",
        "            alpha_CFD, lambd_CFD, r2_CFD, p_CFD = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        para_samples.append({\n",
        "            'ID': row['ID'],\n",
        "            'Alpha_CFD': alpha_CFD,\n",
        "            'Lambda_CFD': lambd_CFD,\n",
        "            'R2_CFD': r2_CFD,\n",
        "            'p_value_CFD': p_CFD,\n",
        "        })\n",
        "    return pd.DataFrame(para_samples)\n",
        "\n",
        "\n",
        "# Run the fitting function\n",
        "para_samples = merge_and_fit_cdf(data_df)\n",
        "merged_df = pd.merge(data_df, para_samples, on='ID', how='left')\n",
        "merged_df.to_excel(file_path, index=False)\n",
        "print(f\"✅ Results successfully saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "_P7En_CfVMFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mass Calculation-CFD-based Method"
      ],
      "metadata": {
        "id": "UpumK57XUW6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mass Calculation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.integrate import quad\n",
        "\n",
        "# File path\n",
        "file_path = 'DATA_WITH_CDF_LIST.xlsx'\n",
        "data_df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "R_fiber = 0.01\n",
        "Rho_fiber = 1.35\n",
        "Rho_fragment = 0.92\n",
        "xmin = 0.1\n",
        "\n",
        "x_intervals = [0.1]\n",
        "\n",
        "\n",
        "def calculate_cdfCFD(x, alpha, lambd):\n",
        "    return 1 - np.exp(-lambd * x**alpha)\n",
        "\n",
        "def calculate_interval_particles(cdf_func, x_min, x_max, total_data, **params):\n",
        "    return total_data * (cdf_func(x_max, **params) - cdf_func(x_min, **params)) / cdf_func(5 + xmin, **params)\n",
        "\n",
        "# Calculate fiber mass\n",
        "def calculate_fiber_mass_cylinder_Simon6(L):\n",
        "    return np.pi * R_fiber**2 * L * Rho_fiber * 0.6 / 1000\n",
        "\n",
        "# Calculate fragment mass\n",
        "def calculate_fragment_mass_elliosoid_Han(L):\n",
        "    return np.pi / 6 * L**2 * 0.02 * Rho_fragment / 1000\n",
        "\n",
        "methods = {\n",
        "    \"CFD\": {\n",
        "        \"fiber_cdf\": calculate_cdfCFD,\n",
        "        \"fiber_mass\": calculate_fiber_mass_cylinder_Simon6,\n",
        "        \"fragment_cdf\": calculate_cdfCFD,\n",
        "        \"fragment_mass\": calculate_fragment_mass_elliosoid_Han\n",
        "    },\n",
        "}\n",
        "\n",
        "def save_mass_data(interval):\n",
        "    data = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        results = {\"ID\": row['ID']}  # {\"ID\": idx + 1}\n",
        "        fiber_size = row['Fiber Number Concentration']\n",
        "        fragment_size = row['Fragment Number Concentration']\n",
        "        alp_CFD = row['Alpha_CFD']\n",
        "        lam_CFD = row['Lambda_CFD']\n",
        "\n",
        "        for method_name, method in methods.items():\n",
        "            total_fiber_mass = 0\n",
        "            total_fragment_mass = 0\n",
        "\n",
        "            for i in np.arange(xmin, 5 + xmin, interval):\n",
        "                mid_point = i + interval / 2\n",
        "\n",
        "                if method['fiber_cdf'] == calculate_cdfCFD:\n",
        "                    fiber_particles = calculate_interval_particles(\n",
        "                        method['fiber_cdf'], i, i + interval, fiber_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "\n",
        "                fiber_mass = fiber_particles * method['fiber_mass'](mid_point)\n",
        "                total_fiber_mass += fiber_mass\n",
        "\n",
        "                if method['fragment_cdf'] == calculate_cdfCFD:\n",
        "                    fragment_particles = calculate_interval_particles(\n",
        "                        method['fragment_cdf'], i, i + interval, fragment_size,\n",
        "                        alpha=alp_CFD, lambd=lam_CFD\n",
        "                    )\n",
        "                fragment_mass = fragment_particles * method['fragment_mass'](mid_point)\n",
        "                total_fragment_mass += fragment_mass\n",
        "\n",
        "            total_mass = total_fiber_mass + total_fragment_mass\n",
        "\n",
        "            results[f\"Fiber Mass ({method_name})\"] = total_fiber_mass\n",
        "            results[f\"Fragment Mass ({method_name})\"] = total_fragment_mass\n",
        "            results[f\"Total Mass ({method_name})\"] = total_mass\n",
        "            # results[f\"b/a{method_name}\"] = balance / total_mass\n",
        "            # results[f\"a/b{method_name}\"] = total_mass / balance\n",
        "            # results[f\"RE{method_name}\"] = abs(total_mass - balance) / balance\n",
        "            # results[f\"SE{method_name}\"] = (total_mass - balance)**2\n",
        "\n",
        "        data.append(results)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    merged_df = pd.merge(data_df, df, on='ID', how='left')\n",
        "    merged_df.to_excel(file_path, index=False)\n",
        "    print(f\"✅ Results successfully saved to {file_path}\")\n",
        "\n",
        "for interval in x_intervals:\n",
        "    save_mass_data(interval)\n"
      ],
      "metadata": {
        "id": "T19SGcV9UW6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}